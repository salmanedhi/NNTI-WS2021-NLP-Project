{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch as torch\n",
    "from torch import nn\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math as mt\n",
    "import time\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import helper\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"#\"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "url = 'https://raw.githubusercontent.com/salmanedhi/NNTI-WS2021-NLP-Project/main/data/hindi_hatespeech.tsv'\n",
    "\n",
    "data = pd.read_csv(url, sep='\\t')\n",
    "    \n",
    "#data = pd.read_csv('data/hindi_hatespeech.tsv', sep='\\t')\n",
    "data_development = shuffle(data)\n",
    "labels = data_development['task_2']\n",
    "# data_development = data\n",
    "type(data_development['task_1'])\n",
    "\n",
    "print(\"Done\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  4665\n",
      "Total words: 141550\n",
      "Unique words: 19836\n"
     ]
    }
   ],
   "source": [
    "#Stopwords Removal\n",
    "sentences = helper.apply_stopword_removal(data_development)\n",
    "print(\"Number of sentences: \" , len(sentences))\n",
    "\n",
    "#Building Vocabulary\n",
    "V, non_unique = helper.build_vocabulary(sentences)\n",
    "print('Total words:', len(non_unique))\n",
    "print('Unique words:', len(V))\n",
    "embedding_size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(\n",
      "  (fc1): Linear(in_features=19836, out_features=640, bias=True)\n",
      "  (fc2): Linear(in_features=640, out_features=19836, bias=True)\n",
      ")\n",
      "torch.Size([19837, 640]) torch.Size([640, 19836])\n"
     ]
    }
   ],
   "source": [
    "#Load Word2Vec embeddings module\n",
    "weights1, weights2 = helper.load_word2vec_embeddings('model_param_hindi', device, len(V), embedding_size)\n",
    "print(weights1.shape, weights2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4665, 132)\n",
      "(4665,)\n"
     ]
    }
   ],
   "source": [
    "## create number array of sentences (replace each word with each numeric value)\n",
    "x_data, max_len_curr = helper.sentence_to_numeric_arr(sentences, V)\n",
    "\n",
    "## apply padding\n",
    "padded = np.array(helper.padding(x_data, max_len_curr))\n",
    "\n",
    "print(padded.shape)\n",
    "encoded_labels = [0 if label == \"NONE\" else 1 for label in labels]\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "print(encoded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#split data into train, valid & test set\n",
    "batch_size = 64\n",
    "train_loader, test_loader = helper.split_data_train_valid_test(padded, encoded_labels, batch_size)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-893d87a531af>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(net.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 Training Loss: 0.6798\n",
      "Epoch: 2/20 Training Loss: 0.5991\n",
      "Epoch: 3/20 Training Loss: 0.4180\n",
      "Epoch: 4/20 Training Loss: 0.2473\n",
      "Epoch: 5/20 Training Loss: 0.1422\n",
      "Epoch: 6/20 Training Loss: 0.0978\n",
      "Epoch: 7/20 Training Loss: 0.0693\n",
      "Epoch: 8/20 Training Loss: 0.0423\n",
      "Epoch: 9/20 Training Loss: 0.0299\n",
      "Epoch: 10/20 Training Loss: 0.0275\n",
      "Epoch: 11/20 Training Loss: 0.0222\n",
      "Epoch: 12/20 Training Loss: 0.0244\n",
      "Epoch: 13/20 Training Loss: 0.0224\n",
      "Epoch: 14/20 Training Loss: 0.0135\n",
      "Epoch: 15/20 Training Loss: 0.0174\n",
      "Epoch: 16/20 Training Loss: 0.0191\n",
      "Epoch: 17/20 Training Loss: 0.0123\n",
      "Epoch: 18/20 Training Loss: 0.0169\n",
      "Epoch: 19/20 Training Loss: 0.0158\n",
      "Epoch: 20/20 Training Loss: 0.0121\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net, criterion = helper.initialize_SentimentLSTM_model_task3(len(V) + 1, batch_size, embedding_size, 32, 1, 2, device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001, amsgrad=True)\n",
    "print_every = 100\n",
    "step = 0\n",
    "n_epochs = 20  # validation loss increases from ~ epoch 3 or 4\n",
    "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
    "\n",
    "\n",
    "training_loss_epoches = []\n",
    "for epoch in range(n_epochs):\n",
    "    h = net.init_hidden(batch_size, device)\n",
    "    training_loss = []\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         print(i, inputs.shape, labels.shape)\n",
    "        # making requires_grad = False for the latest set of h\n",
    "        h = tuple([each.data for each in h])   \n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs, batch_size)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        training_loss.append(loss.item())\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if (step % print_every) == 0:            \n",
    "#             ######################\n",
    "#             ##### VALIDATION #####\n",
    "#             ######################\n",
    "#             net.eval()\n",
    "#             valid_losses = []\n",
    "#             v_h = net.init_hidden(batch_size, device)\n",
    "            \n",
    "#             for v_inputs, v_labels in valid_loader:\n",
    "#                 v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#                 v_h = tuple([each.data for each in v_h])\n",
    "                \n",
    "#                 v_output, v_h = net(v_inputs, batch_size)\n",
    "#                 v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "#                 valid_losses.append(v_loss.item())\n",
    "\n",
    "#             print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "#                   \"Step: {}\".format(step),\n",
    "#                   \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "#                   \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "#             net.train()\n",
    "    training_loss_epoches.append(np.mean(training_loss))\n",
    "    print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "          \"Training Loss: {:.4f}\".format(np.mean(training_loss)))\n",
    "plt.plot(np.linspace(1, len(training_loss_epoches), len(training_loss_epoches)).astype(int), training_loss_epoches)\n",
    "plt.savefig('Task3_hindi.png') \n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1328\n",
      "Test Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "test_h = net.init_hidden(batch_size, device)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    test_h = tuple([each.data for each in test_h])\n",
    "    try:\n",
    "        test_output, test_h = net(inputs.to(device), batch_size)\n",
    "    except IndexError:\n",
    "        print(inputs)\n",
    "#     print(labels.dtype, test_output.dtype)\n",
    "#     print(inputs)\n",
    "    loss = criterion(test_output.detach().to(device), labels.float().to(device))\n",
    "    test_losses.append(loss.item())\n",
    "    \n",
    "    preds = torch.round(test_output.squeeze())\n",
    "    correct_tensor = preds.eq(labels.float().view_as(preds).to(device))\n",
    "    correct = np.squeeze(correct_tensor.cpu().detach().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    \n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Bengali Data on Hindi Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4665, 3) (4665,)\n",
      "Number of sentences:  4665\n",
      "Total words: 64027\n",
      "Unique words: 14482\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Reading Bengali data\n",
    "bengali_data, labels = helper.get_bengali_data('data/bengali_hatespeech.csv')\n",
    "# print(bengali_data)\n",
    "print(bengali_data.shape, labels.shape)\n",
    "bengali_sentences = helper.apply_stopword_removal(bengali_data)\n",
    "print(\"Number of sentences: \" , len(bengali_sentences))\n",
    "\n",
    "## Building Vocabulary\n",
    "bengali_V, bengali_non_unique = helper.build_vocabulary(bengali_sentences)\n",
    "print('Total words:', len(bengali_non_unique))\n",
    "print('Unique words:', len(bengali_V))\n",
    "\n",
    "## Sentence to numeric array\n",
    "x_data_bengali, max_len_curr = helper.sentence_to_numeric_arr(bengali_sentences, bengali_V)\n",
    "\n",
    "## Apply Padding\n",
    "padded = np.array(helper.padding(x_data_bengali, max_len_curr))\n",
    "\n",
    "train_loader, test_loader = helper.split_data_train_valid_test(padded, labels, 64)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-fcf209974ed7>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(net.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Training Loss: 0.6884\n",
      "Epoch: 2/30 Training Loss: 0.5121\n",
      "Epoch: 3/30 Training Loss: 0.2281\n",
      "Epoch: 4/30 Training Loss: 0.1111\n",
      "Epoch: 5/30 Training Loss: 0.0707\n",
      "Epoch: 6/30 Training Loss: 0.0484\n",
      "Epoch: 7/30 Training Loss: 0.0410\n",
      "Epoch: 8/30 Training Loss: 0.0292\n",
      "Epoch: 9/30 Training Loss: 0.0208\n",
      "Epoch: 10/30 Training Loss: 0.0159\n",
      "Epoch: 11/30 Training Loss: 0.0127\n",
      "Epoch: 12/30 Training Loss: 0.0115\n",
      "Epoch: 13/30 Training Loss: 0.0080\n",
      "Epoch: 14/30 Training Loss: 0.0071\n",
      "Epoch: 15/30 Training Loss: 0.0064\n",
      "Epoch: 16/30 Training Loss: 0.0058\n",
      "Epoch: 17/30 Training Loss: 0.0051\n",
      "Epoch: 18/30 Training Loss: 0.0052\n",
      "Epoch: 19/30 Training Loss: 0.0047\n",
      "Epoch: 20/30 Training Loss: 0.0063\n",
      "Epoch: 21/30 Training Loss: 0.0038\n",
      "Epoch: 22/30 Training Loss: 0.0035\n",
      "Epoch: 23/30 Training Loss: 0.0082\n",
      "Epoch: 24/30 Training Loss: 0.0251\n",
      "Epoch: 25/30 Training Loss: 0.0184\n",
      "Epoch: 26/30 Training Loss: 0.0187\n",
      "Epoch: 27/30 Training Loss: 0.0111\n",
      "Epoch: 28/30 Training Loss: 0.0066\n",
      "Epoch: 29/30 Training Loss: 0.0042\n",
      "Epoch: 30/30 Training Loss: 0.0049\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net, criterion = helper.initialize_SentimentLSTM_model_task3_bengali(len(V) + 1, batch_size, embedding_size, 32, 1, 2, device, weights1)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001, amsgrad=True)\n",
    "print_every = 100\n",
    "step = 0\n",
    "n_epochs = 30  # validation loss increases from ~ epoch 3 or 4\n",
    "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
    "\n",
    "\n",
    "training_loss_epoches = []\n",
    "for epoch in range(n_epochs):\n",
    "    h = net.init_hidden(batch_size, device)\n",
    "    training_loss = []\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         print(i, inputs.shape, labels.shape)\n",
    "        # making requires_grad = False for the latest set of h\n",
    "        h = tuple([each.data for each in h])   \n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs, batch_size)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        training_loss.append(loss.item())\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if (step % print_every) == 0:            \n",
    "#             ######################\n",
    "#             ##### VALIDATION #####\n",
    "#             ######################\n",
    "#             net.eval()\n",
    "#             valid_losses = []\n",
    "#             v_h = net.init_hidden(batch_size, device)\n",
    "            \n",
    "#             for v_inputs, v_labels in valid_loader:\n",
    "#                 v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#                 v_h = tuple([each.data for each in v_h])\n",
    "                \n",
    "#                 v_output, v_h = net(v_inputs, batch_size)\n",
    "#                 v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "#                 valid_losses.append(v_loss.item())\n",
    "\n",
    "#             print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "#                   \"Step: {}\".format(step),\n",
    "#                   \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "#                   \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "#             net.train()\n",
    "    training_loss_epoches.append(np.mean(training_loss))\n",
    "    print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "          \"Training Loss: {:.4f}\".format(np.mean(training_loss)))\n",
    "\n",
    "plt.plot(np.linspace(1, len(training_loss_epoches), len(training_loss_epoches)).astype(int), training_loss_epoches)\n",
    "plt.savefig(\"Task3_transfer_learning.png\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5072\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "test_h = net.init_hidden(batch_size, device)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    test_h = tuple([each.data for each in test_h])\n",
    "    try:\n",
    "        test_output, test_h = net(inputs.to(device), batch_size)\n",
    "    except IndexError:\n",
    "        print(inputs)\n",
    "#     print(labels.dtype, test_output.dtype)\n",
    "#     print(inputs)\n",
    "    loss = criterion(test_output.detach().to(device), labels.float().to(device))\n",
    "    test_losses.append(loss.item())\n",
    "    \n",
    "    preds = torch.round(test_output.squeeze())\n",
    "    correct_tensor = preds.eq(labels.float().view_as(preds).to(device))\n",
    "    correct = np.squeeze(correct_tensor.cpu().detach().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    \n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifier on Bengali embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-dc5aab19ce58>:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(net.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 Training Loss: 0.6895\n",
      "Epoch: 2/50 Training Loss: 0.5946\n",
      "Epoch: 3/50 Training Loss: 0.3771\n",
      "Epoch: 4/50 Training Loss: 0.2356\n",
      "Epoch: 5/50 Training Loss: 0.1515\n",
      "Epoch: 6/50 Training Loss: 0.1064\n",
      "Epoch: 7/50 Training Loss: 0.0791\n",
      "Epoch: 8/50 Training Loss: 0.0661\n",
      "Epoch: 9/50 Training Loss: 0.0579\n",
      "Epoch: 10/50 Training Loss: 0.0411\n",
      "Epoch: 11/50 Training Loss: 0.0413\n",
      "Epoch: 12/50 Training Loss: 0.0342\n",
      "Epoch: 13/50 Training Loss: 0.0290\n",
      "Epoch: 14/50 Training Loss: 0.0206\n",
      "Epoch: 15/50 Training Loss: 0.0243\n",
      "Epoch: 16/50 Training Loss: 0.0210\n",
      "Epoch: 17/50 Training Loss: 0.0177\n",
      "Epoch: 18/50 Training Loss: 0.0166\n",
      "Epoch: 19/50 Training Loss: 0.0180\n",
      "Epoch: 20/50 Training Loss: 0.0222\n",
      "Epoch: 21/50 Training Loss: 0.0145\n",
      "Epoch: 22/50 Training Loss: 0.0177\n",
      "Epoch: 23/50 Training Loss: 0.0154\n",
      "Epoch: 24/50 Training Loss: 0.0098\n",
      "Epoch: 25/50 Training Loss: 0.0095\n",
      "Epoch: 26/50 Training Loss: 0.0088\n",
      "Epoch: 27/50 Training Loss: 0.0120\n",
      "Epoch: 28/50 Training Loss: 0.0094\n",
      "Epoch: 29/50 Training Loss: 0.0093\n",
      "Epoch: 30/50 Training Loss: 0.0103\n",
      "Epoch: 31/50 Training Loss: 0.0076\n",
      "Epoch: 32/50 Training Loss: 0.0106\n",
      "Epoch: 33/50 Training Loss: 0.0074\n",
      "Epoch: 34/50 Training Loss: 0.0075\n",
      "Epoch: 35/50 Training Loss: 0.0066\n",
      "Epoch: 36/50 Training Loss: 0.0086\n",
      "Epoch: 37/50 Training Loss: 0.0082\n",
      "Epoch: 38/50 Training Loss: 0.0063\n",
      "Epoch: 39/50 Training Loss: 0.0066\n",
      "Epoch: 40/50 Training Loss: 0.0046\n",
      "Epoch: 41/50 Training Loss: 0.0066\n",
      "Epoch: 42/50 Training Loss: 0.0073\n",
      "Epoch: 43/50 Training Loss: 0.0047\n",
      "Epoch: 44/50 Training Loss: 0.0094\n",
      "Epoch: 45/50 Training Loss: 0.0072\n",
      "Epoch: 46/50 Training Loss: 0.0080\n",
      "Epoch: 47/50 Training Loss: 0.0084\n",
      "Epoch: 48/50 Training Loss: 0.0065\n"
     ]
    }
   ],
   "source": [
    "net, criterion = helper.initialize_SentimentLSTM_model_task3(len(bengali_V) + 1, batch_size, embedding_size, 32, 1, 2, device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001, amsgrad=True)\n",
    "print_every = 100\n",
    "step = 0\n",
    "n_epochs = 50  # validation loss increases from ~ epoch 3 or 4\n",
    "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
    "\n",
    "\n",
    "training_loss_epoches = []\n",
    "for epoch in range(n_epochs):\n",
    "    h = net.init_hidden(batch_size, device)\n",
    "    training_loss = []\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        h = tuple([each.data for each in h])   \n",
    "        \n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs, batch_size)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        training_loss.append(loss.item())\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if (step % print_every) == 0:            \n",
    "#             ######################\n",
    "#             ##### VALIDATION #####\n",
    "#             ######################\n",
    "#             net.eval()\n",
    "#             valid_losses = []\n",
    "#             v_h = net.init_hidden(batch_size, device)\n",
    "            \n",
    "#             for v_inputs, v_labels in valid_loader:\n",
    "#                 v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#                 v_h = tuple([each.data for each in v_h])\n",
    "                \n",
    "#                 v_output, v_h = net(v_inputs, batch_size)\n",
    "#                 v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "#                 valid_losses.append(v_loss.item())\n",
    "\n",
    "#             print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "#                   \"Step: {}\".format(step),\n",
    "#                   \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "#                   \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "#             net.train()\n",
    "    training_loss_epoches.append(np.mean(training_loss))\n",
    "    print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "          \"Training Loss: {:.4f}\".format(np.mean(training_loss)))\n",
    "\n",
    "plt.plot(np.linspace(1, len(training_loss_epoches), len(training_loss_epoches)).astype(int), training_loss_epoches)\n",
    "plt.savefig(\"Task3_bengali.png\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5006\n",
      "Test Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "# import os \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "net.eval()\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "test_h = net.init_hidden(batch_size, device)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    test_h = tuple([each.data for each in test_h])\n",
    "    try:\n",
    "        test_output, test_h = net(inputs.to(device), batch_size)\n",
    "    except IndexError:\n",
    "        print(inputs)\n",
    "#     print(labels.dtype, test_output.dtype)\n",
    "#     print(inputs)\n",
    "    loss = criterion(test_output.detach().to(device), labels.float().to(device))\n",
    "    test_losses.append(loss.item())\n",
    "    \n",
    "    preds = torch.round(test_output.squeeze())\n",
    "    \n",
    "    \n",
    "    correct_tensor = preds.eq(labels.float().view_as(preds).to(device))\n",
    "    correct = np.squeeze(correct_tensor.cpu().detach().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "    \n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt Implementation\n",
    "### Note: Hyperopt was used for the selection of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hyperopt(space)\n",
    "    learning_rate = space['learning_rate']\n",
    "    n_epochs = space['epochs']\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, amsgrad=True)\n",
    "    clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
    "    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "    training_loss_epoches = []\n",
    "    for epoch in range(n_epochs):\n",
    "        h = net.init_hidden(batch_size, device)\n",
    "        training_loss = []\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            h = tuple([each.data for each in h])\n",
    "            net.zero_grad()\n",
    "            output, h = net(inputs, batch_size)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            training_loss.append(loss.item())\n",
    "            nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "    net.eval()\n",
    "    valid_losses = []\n",
    "    v_h = net.init_hidden(batch_size, device)\n",
    "\n",
    "    for v_inputs, v_labels in valid_loader:\n",
    "        v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        v_h = tuple([each.data for each in v_h])\n",
    "\n",
    "        v_output, v_h = net(v_inputs, batch_size)\n",
    "        v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "        valid_losses.append(v_loss.item())\n",
    "        \n",
    "        np.mean(valid_losses)\n",
    "        return {'loss': np.mean(valid_losses), 'model': net, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "        'learning_rate': hp.quniform('learning_rate', 0.001, 0.04, 0.005),\n",
    "        'epochs': hp.quniform('epochs', 20, 200, 20),\n",
    "        'train': train_loader,\n",
    "        'y_train': y_train.to_numpy(),\n",
    "        'val': val_loader}\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=train_hyperopt,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=int(max_evals),\n",
    "                trials=trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
